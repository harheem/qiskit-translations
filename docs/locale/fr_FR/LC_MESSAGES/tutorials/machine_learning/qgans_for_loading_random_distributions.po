msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2020-10-16 16:08+0000\n"
"PO-Revision-Date: 2020-10-19 12:32\n"
"Last-Translator: \n"
"Language-Team: French\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.8.0\n"
"Plural-Forms: nplurals=2; plural=(n > 1);\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: fr\n"
"X-Crowdin-File: /master/docs/locale/en/LC_MESSAGES/tutorials/machine_learning/qgans_for_loading_random_distributions.po\n"
"X-Crowdin-File-ID: 9392\n"
"Language: fr_FR\n"

#: ../../tutorials/machine_learning/qgans_for_loading_random_distributions.ipynb:10
msgid "This page was generated from `tutorials/machine_learning/qgans_for_loading_random_distributions.ipynb`__."
msgstr "Cette page a été générée depuis `tutorials/machine_learning/qgans_for_loading_random_distributions.ipynb`__."

#: ../../tutorials/machine_learning/qgans_for_loading_random_distributions.ipynb:9
msgid "**qGANs for Loading Random Distributions**"
msgstr "**qGANs pour le chargement aléatoire de distributions (Loading Random Distributions)**"

#: ../../tutorials/machine_learning/qgans_for_loading_random_distributions.ipynb:21
msgid "Introduction"
msgstr "Introduction"

#: ../../tutorials/machine_learning/qgans_for_loading_random_distributions.ipynb:23
msgid "Given :math:`k`-dimensional data samples, we employ a quantum Generative Adversarial Network (qGAN) to learn the data's underlying random distribution and to load it directly into a quantum state:"
msgstr "A partir des données d'exemple :math:`k`-dimensional, nous utilisons un réseau antagoniste génératif quantique (quantum Generative Adversarial Network (qGAN)) pour apprendre la distribution aléatoire sous-jacente des données et la charger directement dans un état quantique:"

#: ../../tutorials/machine_learning/qgans_for_loading_random_distributions.ipynb:25
msgid "\\big| g_{\\theta}\\rangle = \\sum_{j=0}^{2^n-1} \\sqrt{p_{\\theta}^{j}}\\big| j \\rangle\n\n"
msgstr "\\big| g_{\\theta}\\rangle = \\sum_{j=0}^{2^n-1} \\sqrt{p_{\\theta}^{j}}\\big| j \\rangle\n\n"

#: ../../tutorials/machine_learning/qgans_for_loading_random_distributions.ipynb:27
msgid "where :math:`p_{\\theta}^{j}` describe the occurrence probabilities of the basis states :math:`\\big| j\\rangle`."
msgstr "où :math:`p_{\\theta}^{j}` décrit la probabilité de l'occurrence des états de base :math:`\\big| j\\rangle`."

#: ../../tutorials/machine_learning/qgans_for_loading_random_distributions.ipynb:29
msgid "The aim of the qGAN training is to generate a state :math:`\\big| g_{\\theta}\\rangle` where :math:`p_{\\theta}^{j}`, for :math:`j\\in \\left\\{0, \\ldots, {2^n-1} \\right\\}`, describe a probability distribution that is close to the distribution underlying the training data :math:`X=\\left\\{x^0, \\ldots, x^{k-1} \\right\\}`."
msgstr "Le but de l'apprentissage qGAN est de générer un état :math:`\\big| g_{\\theta}\\rangle`où :math:`p_{\\theta}^{j}`, pour :math:`j\\in \\left\\{0, \\ldots, {2^n-1} \\right\\}`, décrit la probabilité de distribution qui est proche de la distribution sous-jacente des données d'apprentissage :math:`X=\\left\\{x^0, \\ldots, x^{k-1} \\right\\}`."

#: ../../tutorials/machine_learning/qgans_for_loading_random_distributions.ipynb:31
msgid "For further details please refer to Quantum Generative Adversarial Networks for Learning and Loading Random Distributions. Zoufal, Lucchi, Woerner. 2019."
msgstr "Pour plus de détails, merci de vous référer à \"Réseaux Antagonistes Génératifs Quantique pour l'Apprentissage et le chargement de distribution aléatoire\" (Quantum Generative Adversarial Networks for Learning and Loading Random Distributions). Zoufal, Lucchi, Woerner. 2019."

#: ../../tutorials/machine_learning/qgans_for_loading_random_distributions.ipynb:33
msgid "How to use a trained qGAN in an application, i.e., pricing of financial derivatives, is illustrated here: qGAN Option Pricing."
msgstr "Comment utiliser et entrainer qGAN dans une application, par exemple, la tarification des dérivés financiers, illustrée ici : option de tarification Gan."

#: ../../tutorials/machine_learning/qgans_for_loading_random_distributions.ipynb:71
msgid "Load the Training Data"
msgstr "Chargement des données d'apprentissage"

#: ../../tutorials/machine_learning/qgans_for_loading_random_distributions.ipynb:73
msgid "First, we need to load the :math:`k`-dimensional training data samples (here k=1). Next, the data resolution is set, i.e. the min/max data values and the number of qubits used to represent each data dimension."
msgstr "Premièrement, nous avons besoin de charger les données d'exemple d'apprentissage :math:`k`-dimensional (ici k=1). Ensuite, les données de résolution sont positionnées, par exemple, les valeurs min/max et le nombre de qbits utilisés pour représenter chaque dimension des données."

#: ../../tutorials/machine_learning/qgans_for_loading_random_distributions.ipynb:108
msgid "Initialize the qGAN"
msgstr "Initialiser le qGAN"

#: ../../tutorials/machine_learning/qgans_for_loading_random_distributions.ipynb:110
msgid "The qGAN consists of a quantum generator :math:`G_{\\theta}`, a variational quantum circuit, and a classical discriminator :math:`D_{\\phi}`, a neural network. To implement the quantum generator, we choose a depth-\\ :math:`1` variational form that implements :math:`R_Y` rotations and :math:`CZ` gates which takes a uniform distribution as an input state. Notably, for :math:`k>1` the generator's parameters must be chosen carefully. For example, the circuit depth should be :math:`>1` because higher circuit depths enable the representation of more complex structures. The classical discriminator is given by a :math:`3`-layer neural network that applies linear transformations, leaky ReLU functions in the hidden layers and a sigmoid function in the output layer. Notably, the neural network is implemented with PyTorch. Please refer to https://pytorch.org/get-started/locally/ for PyTorch installation instructions. Here, both networks are updated with the ADAM optimization algorithm."
msgstr "Le qGAN consiste en un générateur quantique :math:` G_ {\\theta } `, un circuit quantique variationnel, et un discriminateur classique :math:` D_ { \\phi } `, un réseau neuronal. Pour mettre en oeuvre le générateur quantique, nous choisissons une forme de profondeur-\\ :math:` 1 ` variationnelle qui implémente :math:` R_Y rotations et :math:` CZ ` portes qui prend une distribution uniforme en tant qu'état d'entrée. Notamment, pour :math:` k> 1, les paramètres du générateur doivent être choisis avec soin. Par exemple, la profondeur du circuit doit être :math:` >1 ` car des profondeurs de circuit plus élevées permettent la représentation de structures plus complexes. Le discriminateur classique est donné par un réseau neuronal :math:` 3 qui applique des transformations linéaires, des fonctions de ReLU qui fuient dans les couches cachées et une fonction sigmoïde dans la couche de sortie. Notamment, le réseau neuronal est mis en œuvre avec PyTorch. Veuillez consulter le site https://pytorch.org/get-started/locally/ pour les instructions d'installation de PyTorch. Ici, les deux réseaux sont mis à jour avec l'algorithme d'optimisation ADAM."

#: ../../tutorials/machine_learning/qgans_for_loading_random_distributions.ipynb:171
msgid "Run the qGAN Training"
msgstr "Exécuter la formation qGAN"

#: ../../tutorials/machine_learning/qgans_for_loading_random_distributions.ipynb:173
msgid "During the training the discriminator's and the generator's parameters are updated alternately w.r.t the following loss functions:"
msgstr "Pendant la formation, les paramètres du discriminateur et du générateur sont mis à jour alternativement avec les fonctions de perte suivantes:"

#: ../../tutorials/machine_learning/qgans_for_loading_random_distributions.ipynb:175
msgid "L_G\\left(\\phi, \\theta\\right) = -\\frac{1}{m}\\sum\\limits_{l=1}^{m}\\left[\\log\\left(D_{\\phi}\\left(g^{l}\\right)\\right)\\right]\n\n"
"and"
msgstr "L_G \\left (\\phi, \\theta\\right) =-\\frac{1}{m}\\sum\\limits_ { l= 1 } ^{m}\\left [ \\log\\left (D_ { \\phi } \\left (g ^{l}\\right)\\right)\\right ]\n\n"
"et"

#: ../../tutorials/machine_learning/qgans_for_loading_random_distributions.ipynb:179
msgid "    L_D\\left(\\phi, \\theta\\right) =\n"
"      \\frac{1}{m}\\sum\\limits_{l=1}^{m}\\left[\\log D_{\\phi}\\left(x^{l}\\right) + \\log\\left(1-D_{\\phi}\\left(g^{l}\\right)\\right)\\right],\n\n"
"with :math:`m` denoting the batch size and :math:`g^l` describing the data samples generated by the quantum generator."
msgstr "    G_D\\left(\\phi, \\theta\\right) =\n"
"      \\frac{1}{m}\\sum\\limits_{l=1}^{m}\\left[\\log D_{\\phi}\\left(x^{l}\\right) + \\log\\left(1-D_{\\phi}\\left(g^{l}\\right)\\right)\\right],\n\n"
"avec :math:`m` indiquant la taille du lot et :math:`g^l` décrivant les échantillons de données générés par le générateur quantique."

#: ../../tutorials/machine_learning/qgans_for_loading_random_distributions.ipynb:186
msgid "Please note that the training will take a while (:math:`\\sim 20` min)."
msgstr "Veuillez noter que la formation prendra un certain temps (:math:` \\sim 20 ` min)."

#: ../../tutorials/machine_learning/qgans_for_loading_random_distributions.ipynb:238
msgid "Training Progress & Outcome"
msgstr "Progrès & Résultats de la formation"

#: ../../tutorials/machine_learning/qgans_for_loading_random_distributions.ipynb:240
msgid "Now, we plot the evolution of the generator's and the discriminator's loss functions during the training as well as the progress in the relative entropy between the trained and the target distribution. Finally, we also compare the cumulative distribution function (CDF) of the trained distribution to the CDF of the target distribution."
msgstr "Maintenant, nous tracons l'évolution des fonctions de perte du générateur et du discriminateur pendant la formation ainsi que la progression de l'entropie relative entre la distribution formée et la distribution cible. Enfin, nous comparons également la fonction de distribution cumulative (CDF) de la distribution entraînée au CDF de la distribution cible."

